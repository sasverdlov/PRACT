Статистической гипотезой называется предположение о каком-либо свойстве (величине параметра, форме распределения) [[Генеральная совокупность|генеральной совокупности]], которое можно проверить, опираясь на данные выборки.
Гипотезы о параметрах генеральной совокупности называются *параметрическими*, о распределениях – *непараметрическими*.

## Тестирование гипотезы
Тестирование гипотезы - процедура, в которой мы решаем, принять гипотезу или отвергнуть. Это происходит с помощью [[Статистические критерии|статистических критериев]].

Процесс проверки гипотез основан на сравнении двух конкурирующих предположений:

* **Нулевая гипотеза (H₀)**: предполагает отсутствие воздействия или связи.
* **Альтернативная гипотеза (H₁)**: предполагает наличие значимого воздействия.

Нулевая гипотеза считается верной до тех пор, пока доказательства не укажут на обратное. Во время анализа возникает риск совершения двух типов ошибок: ложноположительных и ложноотрицательных результатов ([ошибки I](в%20работе/Ошибка%20I%20типа%20(False%20Positive)) и [II типа](в%20работе/Ошибка%20II%20типа%20(False%20Negative))).

В классическом подходе к проверке гипотез единственным критерием является сравнение [p-значения](Статистические%20методы/P-значение%20в%20статистике) и [α-значения](Ошибка%20I%20типа%20(False%20Positive).md):

`если p < α → отвергаем H₀, иначе - не отвергаем`

Но этого часто недостаточно для надёжных выводов, особенно при сложных или многократных тестах. Вот какие дополнительные критерии можно применять для увеличения надёжности выводов при проверке гипотез:

1. **Коррекция на множественные сравнения**  
    При тестировании сразу нескольких гипотез растёт суммарная вероятность ложноположительного результата для одной или нескольких из них ([семейная ошибка, FWER](Статистические%20методы/Семейная%20ошибка%20(FWER))). Чтобы этого избежать, вместо "p < α" на каждом шаге используют методы контроля [семейной ошибки (FWER)](Статистические%20методы/Семейная%20ошибка%20(FWER)) и ожидаемую долю ложных обнаружений (FDR).
        
2. **Требование минимальной практической значимости (effect size)**  
    Даже если [p-значение](Статистические%20методы/P-значение%20в%20статистике) статистически значимо (скажем, p = 0.03 при α = 0.05), результат воздействия (разница средних, коэффициент корреляции и т. п.) может быть настолько мал, что не имеет прикладного смысла. Жёсткий критерий может предусматривать, что результат воздействия должен превышать заранее оговорённый порог (например, d Коэна ≥ 0.5 для умеренной значимости).
    
3. **Ограничения по ширине доверительного интервала**  
    Вместо одного [p-значения](Статистические%20методы/P-значение%20в%20статистике) требуют, чтобы доверительный интервал для параметра был не только не пересекал "нулевое" значение, но и был достаточно узким - так, чтобы оценка результата воздействия была достаточно точной. Например:
    
    > "95%-доверительный интервал разницы средних лежит в пределах [0.8; 2.1]"  
    > Здесь важно, чтобы интервал не был слишком широк, иначе результат будет мало применим для практических выводов.
    
4. **Байесовские критерии**  
    Вместо или наряду с [p-значением](Статистические%20методы/P-значение%20в%20статистике) используют, например, [фактор Байеса (BF)](в%20работе/Фактор%20Байеса%20(BF)): если BF > 10, доказательства в пользу альтернативной гипотезы считаются "сильными". Это позволяет прямо сравнивать правдоподобие H₀ и H₁, а не просто контролировать частоту ошибок.
    
5. **Предварительная регистрация дизайна (pre-registration)**  
    Чёткое описание гипотез, критериев включения/исключения данных и плана анализа до начала эксперимента исключает "постфактумную подстройку" анализа под желаемый результат. Это дисциплинирует исследователя и уменьшает степень свободы в принятии решений, влияющих на p-значения.
    
6. **Адаптивные и гибридные дизайны**  
    При промежуточных анализах могут корректировать план исследования (например, увеличивать объём выборки), но делают это по заранее оговорённому протоколу с учётом [α-спендинга](в%20работе/α-спендинг), чтобы не нарушить общий уровень ошибок.