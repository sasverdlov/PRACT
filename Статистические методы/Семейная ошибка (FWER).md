
Семейная ошибка (Family-Wise Error Rate, FWER) - это вероятность хотя бы одного ложноположительного результата ([ошибки I типа](Ошибка%20I%20типа%20(False%20Positive).md)) при проведении множества статистических тестов одновременно.
К примеру, если проверять несколько гипотез в рамках одного исследования, FWER - это шанс, что **хотя бы в одном** из этих тестов будет ошибочно отклонена истинная нулевая гипотеза.

### Почему важно контролировать FWER

Каждый отдельный тест ведёт себя так, что при уровне значимости α = 0.05 вероятность [ложноположительного результата](Ошибка%20I%20типа%20(False%20Positive).md) равна 5%. Но если вы проводите несколько тестов:

- При 1 тесте: P(хотя бы одна ошибка) = 0.05
- При 10 независимых тестах:
$$
    P(\text{хотя бы одна ошибка})=1−(1−0.05)^{10}≈1−0.95^{10}≈0.40
$$
    То есть уже ~40% шанс получить хотя бы один [ложноположительный результат](Статистические%20методы/Ошибка%20I%20типа%20(False%20Positive))!

- А при 20 тестах он вырастает до...
$$
1−0.95^{20}≈0.64
$$
    ... целых 64%.

### Как контролировать семейную ошибку

Чтобы ограничить суммарную вероятность [ложноположительных результатов](Ошибка%20I%20типа%20(False%20Positive).md) на уровне α (например, 5%) при множественных сравнениях, используют специальные методы:

1. **Коррекция Бонферрони**  
    Делит общий уровень значимости α на число тестов m и сравнивает каждое [p-значение](Статистические%20методы/P-значение%20в%20статистике) с порогом $$
   \alpha_{\text{каждого}} = \frac{\alpha}{m}
   $$
    
    Таким образом гарантируется FWER ≤ α, но при большом m чрезмерно консервативна (низкая мощность): при m=20 и α=0,05 получается:
    $$
    α_{\text{каждого}}=0,0025
	    $$

	Чтобы получить статистическую значимость, каждое p-[значение](Статистические%20методы/P-значение%20в%20статистике) теперь должно быть меньше 0,0025 вместо 0,05.
    
2. **Метод Холма-Бонферрони**  
    Последовательная (step-down) схема:

	- Отсортируем [p-значения](Статистические%20методы/P-значение%20в%20статистике) по возрастанию:
   $$
   p_{(1)} \le p_{(2)} \le \dots \le p_{(m)}
   $$  
	   и сравним их по схеме:
   $$
   p_{(1)} \le \frac{\alpha}{m},\quad
   p_{(2)} \le \frac{\alpha}{m-1},\quad
   \dots,\quad
   p_{(k)} \le \frac{\alpha}{m-k+1}.
   $$
        Останавливаемся при первом несоответствии.
        Метод менее консервативен, чем простая коррекция Бонферрони, но всё ещё контролирует FWER.
        
3. **Метод Шидака (Sidák)**  
    Предполагает независимость тестов и использует порог
    $$
   \alpha_{\text{каждого}} = 1 - (1 - \alpha)^{\frac{1}{m}}.
   $$
    Немного менее жёсткая альтернатива коррекции Бонферрони.
    
4. **Локально адаптивные коррекции**  
    Например, метод Бенджамини-Хохберга контролирует не FWER, а ожидаемую долю ложных обнаружений FDR (False Discovery Rate). Он менее строгий, даёт большую мощность, но уже не гарантирует жесткий контроль семейной ошибки, а лишь ожидаемую долю ложных обнаружений.
    
